{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO3cLNDfbGE+vMIA+bgY3c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guttulaswathi/ml/blob/main/Assignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.build a multiple linear regression model on a dataset 50_startups"
      ],
      "metadata": {
        "id": "JHteGxJ-37rN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gz6ilodGvHWE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "data = pd.read_csv(\"/content/50_Startups.csv\")\n",
        "data.head()\n",
        "data = pd.get_dummies(data, drop_first=True) # get_dummies() is a function commonly used to converrtion\n",
        "X = data.drop(columns=['Profit'])  # Replace 'Profit' with your dependent variable\n",
        "y = data['Profit']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    metrics = {\n",
        "        'Train R^2': r2_score(y_train, y_train_pred),\n",
        "        'Test R^2': r2_score(y_test, y_test_pred),\n",
        "        'Train MSE': mean_squared_error(y_train, y_train_pred),\n",
        "        'Test MSE': mean_squared_error(y_test, y_test_pred),\n",
        "        'Train MAE': mean_absolute_error(y_train, y_train_pred),\n",
        "        'Test MAE': mean_absolute_error(y_test, y_test_pred)\n",
        "    }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No Regularization"
      ],
      "metadata": {
        "id": "z1YZsuPSpWYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Build a Multiple Linear Regression model\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_metrics = evaluate_model(lr, X_train, X_test, y_train, y_test)\n",
        "print(\"Linear Regression Metrics:\", lr_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHekz-oro9gx",
        "outputId": "59a926b9-1997-452f-ba38-6df04423e576"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Metrics: {'Train R^2': 0.9537019995248526, 'Test R^2': 0.8987266414328637, 'Train MSE': 79700060.08259317, 'Test MSE': 82010363.04430099, 'Train MAE': 6662.656240898313, 'Test MAE': 6961.477813252376}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.apply L1 regularization on the created simple and multiple linear regression. what is your observation"
      ],
      "metadata": {
        "id": "l526ujFA5JV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha=1.0)  # Adjust alpha for stronger regularization\n",
        "lasso.fit(X_train, y_train)\n",
        "lasso_metrics = evaluate_model(lasso, X_train, X_test, y_train, y_test)\n",
        "print(\"Lasso Regression Metrics:\", lasso_metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOPZD1q-0eQP",
        "outputId": "f9dd35eb-431a-4ba4-f5ff-1652c731b5e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso Regression Metrics: {'Train R^2': 0.9537019924129666, 'Test R^2': 0.8987342494230525, 'Train MSE': 79700072.32540563, 'Test MSE': 82004202.15414938, 'Train MAE': 6662.314235709302, 'Test MAE': 6961.5746884671735}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations:\n",
        "\n",
        "# Lasso vs. Ordinary Least Squares (OLS):\n",
        "\n",
        "In OLS, all coefficients are retained, regardless of their importance.\n",
        "\n",
        "In Lasso, irrelevant or less important features might have their coefficients shrunk to zero, effectively performing feature selection.\n",
        "\n",
        "# Impact of Regularization:\n",
        "\n",
        "Increasing the alpha parameter in Lasso strengthens the penalty, leading to more coefficients being reduced to zero.\n",
        "\n",
        "This reduces model complexity but may also lead to underfitting if the penalty is too strong.\n",
        "\n",
        "# Interpretability:\n",
        "\n",
        "Lasso helps in identifying the most relevant features for predicting the target variable.\n",
        "\n",
        "Coefficients set to zero indicate features that do not contribute significantly."
      ],
      "metadata": {
        "id": "d6efW1Ft2e_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.apply L2 regularization on the created simple and multiple linear regression. what is your observation"
      ],
      "metadata": {
        "id": "SQAy1_wv4gKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge(alpha=1.0)  # Adjust alpha for stronger regularization\n",
        "ridge.fit(X_train, y_train)\n",
        "ridge_metrics = evaluate_model(ridge, X_train, X_test, y_train, y_test)\n",
        "print(\"Ridge Regression Metrics:\", ridge_metrics)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whyjsKee04kn",
        "outputId": "fb42a7cb-b3bf-494f-97e4-ee301ab71e0e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression Metrics: {'Train R^2': 0.9537005526831293, 'Test R^2': 0.8988780252113923, 'Train MSE': 79702550.75975187, 'Test MSE': 81887773.66036233, 'Train MAE': 6655.4599147903355, 'Test MAE': 6963.340034795974}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observations:\n",
        "## Ridge vs. Lasso:\n",
        "\n",
        "Ridge shrinks all coefficients proportionally, retaining all features but reducing their influence.\n",
        "\n",
        "Unlike Lasso, Ridge does not perform feature selection (i.e., coefficients are not set to exactly zero).\n",
        "\n",
        "### Impact of Regularization:\n",
        "\n",
        "Increasing the alpha parameter strengthens the penalty, leading to smaller coefficient values.\n",
        "\n",
        "This helps in reducing multicollinearity and overfitting, but too much regularization can lead to underfitting.\n",
        "\n",
        "### Model Complexity:\n",
        "\n",
        "Ridge maintains all features in the model, making it suitable when all predictors are expected to have some contribution to the target.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GVlz7Vn81yEi"
      }
    }
  ]
}